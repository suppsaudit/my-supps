#!/usr/bin/env python3
"""
æ–°ã—ã„Kaggle iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å‡¦ç†
"""

import os
import zipfile
import pandas as pd
from datetime import datetime

def check_and_process_new_dataset():
    """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ãƒ»å‡¦ç†"""
    
    print("ğŸ” æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ç¢ºèª
    zip_files = [f for f in os.listdir('.') if f.endswith('.zip')]
    
    if not zip_files:
        print("âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("\nğŸ“¥ æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †:")
        print("1. https://www.kaggle.com/datasets/crawlfeeds/iherb-products-dataset")
        print("2. 'Download'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
        print("3. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»¥ä¸‹ã«ä¿å­˜:")
        print(f"   {os.getcwd()}/")
        print("4. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œ")
        return False
    
    # æœ€æ–°ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    zip_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    latest_zip = zip_files[0]
    file_size = os.path.getsize(latest_zip)
    
    print(f"ğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«: {latest_zip}")
    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")
    
    # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    if file_size < 2 * 1024 * 1024:  # 2MBæœªæº€
        print("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™")
        print("ğŸ’¡ å®Ÿéš›ã®iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯æ•°MBã‚ã‚‹ã¯ãšã§ã™")
        print("ğŸ’¡ æ­£ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ZIPå±•é–‹
    print(f"ğŸ“‚ {latest_zip} ã‚’å±•é–‹ä¸­...")
    try:
        with zipfile.ZipFile(latest_zip, 'r') as zip_ref:
            file_list = zip_ref.namelist()
            print(f"ğŸ“‹ ZIPå†…å®¹: {file_list}")
            zip_ref.extractall('.')
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        csv_files = [f for f in os.listdir('.') if f.endswith('.csv') and 'iherb' in f.lower()]
        if not csv_files:
            csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]
        
        if csv_files:
            csv_file = csv_files[0]
            csv_size = os.path.getsize(csv_file)
            print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«: {csv_file}")
            print(f"ğŸ“ CSVã‚µã‚¤ã‚º: {csv_size:,} bytes ({csv_size/1024/1024:.1f} MB)")
            return csv_file
        else:
            print("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
    except Exception as e:
        print(f"âŒ ZIPå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_real_iherb_data(csv_file):
    """å®Ÿéš›ã®iHerbãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
    
    print(f"ğŸ“Š {csv_file} ã‚’è©³ç´°åˆ†æä¸­...")
    
    try:
        # ã¾ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨è¡Œæ•°ã‚’æ¨å®š
        line_count = 0
        with open(csv_file, 'r', encoding='utf-8') as f:
            for line in f:
                line_count += 1
                if line_count > 100000:  # 10ä¸‡è¡Œã§ã‚«ã‚¦ãƒ³ãƒˆåœæ­¢
                    break
        
        print(f"ğŸ“ æ¨å®šè¡Œæ•°: {line_count:,}è¡Œä»¥ä¸Š")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯åˆ†å‰²èª­ã¿è¾¼ã¿ï¼‰
        print("ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        if line_count > 50000:
            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æœ€åˆã®50000è¡Œã ã‘èª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_file, nrows=50000, encoding='utf-8')
            print(f"âš ï¸ å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚æœ€åˆã®{len(df):,}è¡Œã®ã¿å‡¦ç†")
        else:
            df = pd.read_csv(csv_file, encoding='utf-8')
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}è¡Œ, {len(df.columns)}åˆ—")
        
        # ã‚«ãƒ©ãƒ è©³ç´°åˆ†æ
        print(f"\nğŸ“‹ å…¨ã‚«ãƒ©ãƒ è©³ç´°:")
        for i, col in enumerate(df.columns, 1):
            non_null_count = df[col].notna().sum()
            unique_count = df[col].nunique()
            print(f"  {i:2d}. {col:<25} (éç©º: {non_null_count:,}, ãƒ¦ãƒ‹ãƒ¼ã‚¯: {unique_count:,})")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        print(f"\nğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
        print(df.head(3).to_string(max_cols=8))
        
        # ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆå•†å“ã®æŠ½å‡º
        print(f"\nğŸ” ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆé–¢é€£å•†å“ã‚’æŠ½å‡ºä¸­...")
        
        supplement_keywords = [
            'vitamin', 'mineral', 'supplement', 'capsule', 'tablet', 'softgel',
            'omega', 'probiotic', 'protein', 'amino', 'magnesium', 'calcium',
            'zinc', 'iron', 'b12', 'b-12', 'multivitamin', 'fish oil'
        ]
        
        supplement_mask = pd.Series([False] * len(df))
        
        # å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ ã‹ã‚‰æ¤œç´¢
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        print(f"ğŸ” æ¤œç´¢å¯¾è±¡ã‚«ãƒ©ãƒ : {text_columns}")
        
        for col in text_columns:
            for keyword in supplement_keywords:
                mask = df[col].astype(str).str.lower().str.contains(keyword, na=False, regex=False)
                supplement_mask |= mask
        
        supplement_df = df[supplement_mask].copy()
        print(f"âœ… ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆå•†å“: {len(supplement_df):,}ä»¶")
        
        # ãƒ–ãƒ©ãƒ³ãƒ‰åˆ†æ
        brand_columns = [col for col in df.columns if 'brand' in col.lower()]
        if brand_columns:
            brand_col = brand_columns[0]
            print(f"\nğŸ“Š ãƒ–ãƒ©ãƒ³ãƒ‰åˆ†æ ({brand_col}):")
            brand_stats = supplement_df[brand_col].value_counts().head(30)
            for brand, count in brand_stats.items():
                print(f"  {brand}: {count:,}ä»¶")
        
        return supplement_df
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def generate_massive_supplement_sql(df):
    """å¤§è¦æ¨¡ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQLç”Ÿæˆ"""
    
    print(f"ğŸ”„ å¤§è¦æ¨¡SQLç”Ÿæˆä¸­... ({len(df):,}ä»¶)")
    
    # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°
    title_cols = [col for col in df.columns if any(word in col.lower() for word in ['title', 'name', 'product'])]
    brand_cols = [col for col in df.columns if 'brand' in col.lower()]
    upc_cols = [col for col in df.columns if any(word in col.lower() for word in ['upc', 'barcode', 'code'])]
    
    title_col = title_cols[0] if title_cols else None
    brand_col = brand_cols[0] if brand_cols else None
    upc_col = upc_cols[0] if upc_cols else None
    
    print(f"ğŸ“‹ ä½¿ç”¨ã‚«ãƒ©ãƒ :")
    print(f"  å•†å“å: {title_col}")
    print(f"  ãƒ–ãƒ©ãƒ³ãƒ‰: {brand_col}")
    print(f"  UPC: {upc_col}")
    
    processed_products = []
    
    for idx, row in df.iterrows():
        try:
            # å•†å“å
            product_name = str(row[title_col]) if title_col and pd.notna(row[title_col]) else f"iHerb Product {idx+1}"
            if len(product_name) > 250:
                product_name = product_name[:250] + "..."
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰
            brand = str(row[brand_col]) if brand_col and pd.notna(row[brand_col]) else "Unknown"
            if len(brand) > 100:
                brand = brand[:100]
            
            # UPC
            upc = str(row[upc_col]) if upc_col and pd.notna(row[upc_col]) else ""
            
            # DSLD ID
            if upc and upc.isdigit() and len(upc) >= 8:
                dsld_id = f"DSLD_{upc}"
            else:
                dsld_id = f"DSLD_IHERB_{idx+1:08d}"
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
            name_lower = product_name.lower()
            if any(word in name_lower for word in ['vitamin c', 'ascorbic']):
                category = 'vitamins'
            elif any(word in name_lower for word in ['vitamin d', 'vitamin e', 'vitamin k', 'vitamin b', 'multivitamin']):
                category = 'vitamins'
            elif any(word in name_lower for word in ['magnesium', 'calcium', 'zinc', 'iron', 'mineral']):
                category = 'minerals'
            elif any(word in name_lower for word in ['omega', 'dha', 'epa', 'fish oil']):
                category = 'fatty_acids'
            elif any(word in name_lower for word in ['protein', 'amino', 'whey']):
                category = 'proteins'
            elif any(word in name_lower for word in ['probiotic']):
                category = 'probiotics'
            else:
                category = 'supplements'
            
            processed_products.append({
                'dsld_id': dsld_id,
                'name_en': product_name,
                'name_ja': product_name,
                'brand': brand,
                'serving_size': '1 serving',
                'category': category
            })
            
        except Exception as e:
            print(f"âš ï¸ è¡Œ {idx} ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"âœ… {len(processed_products):,}ä»¶ã®å•†å“ã‚’å‡¦ç†å®Œäº†")
    
    # SQLç”Ÿæˆ
    sql_content = f"""-- iHerbå…¨ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆKaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
-- å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- ç·å•†å“æ•°: {len(processed_products):,}ä»¶

-- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨å‰Šé™¤
DELETE FROM user_supplements;
DELETE FROM supplement_nutrients;
DELETE FROM supplements;
DELETE FROM nutrients;

-- å…¨ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆå•†å“ã‚’æŠ•å…¥ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
"""
    
    # ãƒãƒƒãƒå‡¦ç†ã§åˆ†å‰²
    batch_size = 1000
    total_batches = (len(processed_products) + batch_size - 1) // batch_size
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, len(processed_products))
        batch_products = processed_products[start_idx:end_idx]
        
        sql_content += f"\n-- ãƒãƒƒãƒ {batch_num + 1}/{total_batches}\n"
        sql_content += "INSERT INTO supplements (dsld_id, name_en, name_ja, brand, serving_size, category) VALUES\n"
        
        for i, product in enumerate(batch_products):
            name_en = product['name_en'].replace("'", "''")
            name_ja = product['name_ja'].replace("'", "''")
            brand = product['brand'].replace("'", "''")
            
            sql_content += f"('{product['dsld_id']}', '{name_en}', '{name_ja}', '{brand}', '{product['serving_size']}', '{product['category']}')"
            
            if i < len(batch_products) - 1:
                sql_content += ",\n"
            else:
                sql_content += ";\n"
    
    # ç‰¹åˆ¥å•†å“è¿½åŠ 
    sql_content += """
-- ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢ç”¨ç‰¹åˆ¥å•†å“
INSERT INTO supplements (dsld_id, name_en, name_ja, brand, serving_size, category) VALUES
('DSLD_19121619', 'NOW Foods Vitamin C-1000 Sustained Release', 'NOW Foods ãƒ“ã‚¿ãƒŸãƒ³C-1000 å¾æ”¾æ€§', 'NOW Foods', '1 tablet', 'vitamins');

-- ãƒ‡ãƒ¼ã‚¿ç¢ºèª
SELECT 'iHerbå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†' as status;
SELECT COUNT(*) as total_products FROM supplements;
SELECT brand, COUNT(*) as count FROM supplements GROUP BY brand ORDER BY count DESC LIMIT 50;
"""
    
    with open('import_massive_iherb.sql', 'w', encoding='utf-8') as f:
        f.write(sql_content)
    
    print("âœ… import_massive_iherb.sql ã‚’ç”Ÿæˆå®Œäº†")
    return len(processed_products)

if __name__ == "__main__":
    print("ğŸš€ æ–°ã—ã„Kaggle iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†é–‹å§‹")
    print("=" * 80)
    
    # 1. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
    csv_file = check_and_process_new_dataset()
    if not csv_file:
        exit(1)
    
    # 2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    df = process_real_iherb_data(csv_file)
    if df is None or len(df) == 0:
        print("âŒ ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆå•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        exit(1)
    
    # 3. SQLç”Ÿæˆ
    total_count = generate_massive_supplement_sql(df)
    
    print("=" * 80)
    print(f"ğŸ‰ å‡¦ç†å®Œäº†! {total_count:,}ä»¶ã®ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆå•†å“ã‚’SQLåŒ–")
    print("ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: import_massive_iherb.sql")
    print("ğŸ“Š ã“ã‚Œã§æ•°ä¸‡ä»¶ã®ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå®Œæˆï¼")