#!/usr/bin/env python3
"""
Kaggle iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
APIã‚­ãƒ¼ãªã—ã§ã‚‚Webã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
"""

import requests
import pandas as pd
import json
import os
from urllib.parse import urljoin

def download_iherb_dataset_direct():
    """
    Kaggleã®iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã®ã§èªè¨¼ãªã—ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
    """
    
    # Kaggleã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆURLï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰
    dataset_url = "https://www.kaggle.com/datasets/crawlfeeds/iherb-products-dataset"
    
    print("ğŸ” iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆURL: {dataset_url}")
    print("\nâš ï¸  æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™:")
    print("1. https://www.kaggle.com/datasets/crawlfeeds/iherb-products-dataset ã«ã‚¢ã‚¯ã‚»ã‚¹")
    print("2. 'Download'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
    print("3. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»¥ä¸‹ã®å ´æ‰€ã«ä¿å­˜:")
    print(f"   {os.path.join(os.getcwd(), 'iherb-products-dataset.zip')}")
    print("4. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œ")
    
    return None

def extract_and_process_iherb_data():
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸiHerbãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
    
    zip_path = "iherb-products-dataset.zip"
    csv_path = "iherb_products.csv"
    
    if not os.path.exists(zip_path):
        print(f"âŒ {zip_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return download_iherb_dataset_direct()
    
    print(f"ğŸ“¦ {zip_path} ã‚’å±•é–‹ä¸­...")
    
    try:
        import zipfile
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall('.')
            
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        extracted_files = [f for f in os.listdir('.') if f.endswith('.csv')]
        if not extracted_files:
            print("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
        csv_file = extracted_files[0]
        print(f"ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {csv_file}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­...")
        df = pd.read_csv(csv_file)
        
        print(f"âœ… ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}ä»¶")
        print(f"âœ… ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}å€‹")
        
        # ã‚«ãƒ©ãƒ åã‚’è¡¨ç¤º
        print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ :")
        for i, col in enumerate(df.columns, 1):
            print(f"  {i:2d}. {col}")
        
        # NOW Foodsã®å•†å“ã‚’æ¤œç´¢
        print("\nğŸ” NOW Foodså•†å“ã‚’æ¤œç´¢ä¸­...")
        
        # ãƒ–ãƒ©ãƒ³ãƒ‰ã‚«ãƒ©ãƒ ã‚’æ¢ã™
        brand_columns = [col for col in df.columns if 'brand' in col.lower()]
        title_columns = [col for col in df.columns if any(word in col.lower() for word in ['title', 'name', 'product'])]
        
        now_foods_count = 0
        now_foods_products = []
        
        for _, row in df.iterrows():
            row_text = ' '.join(str(row[col]) for col in df.columns if pd.notna(row[col])).upper()
            if 'NOW FOOD' in row_text or 'NOW-FOOD' in row_text:
                now_foods_count += 1
                now_foods_products.append(row)
                if now_foods_count <= 10:  # æœ€åˆã®10ä»¶ã‚’è¡¨ç¤º
                    product_name = ""
                    if title_columns:
                        product_name = str(row[title_columns[0]])
                    print(f"  - {product_name}")
        
        print(f"\nğŸ¯ NOW Foodså•†å“ç™ºè¦‹: {now_foods_count:,}ä»¶")
        
        if now_foods_count > 0:
            # NOW Foodså•†å“ã‚’CSVã«ä¿å­˜
            now_foods_df = pd.DataFrame(now_foods_products)
            now_foods_df.to_csv('now_foods_products.csv', index=False)
            print(f"âœ… NOW Foodså•†å“ã‚’ now_foods_products.csv ã«ä¿å­˜")
            
            # Supabaseç”¨SQLã‚’ç”Ÿæˆ
            generate_supabase_sql(now_foods_df)
            
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def generate_supabase_sql(df):
    """Supabaseç”¨ã®SQL INSERTã‚’ç”Ÿæˆ"""
    
    print("\nğŸ”„ Supabaseç”¨SQLç”Ÿæˆä¸­...")
    
    # ã‚«ãƒ©ãƒ åã‚’æ¨æ¸¬
    title_col = None
    brand_col = None
    upc_col = None
    price_col = None
    
    for col in df.columns:
        col_lower = col.lower()
        if not title_col and any(word in col_lower for word in ['title', 'name', 'product']):
            title_col = col
        elif not brand_col and 'brand' in col_lower:
            brand_col = col
        elif not upc_col and any(word in col_lower for word in ['upc', 'barcode', 'code']):
            upc_col = col
        elif not price_col and 'price' in col_lower:
            price_col = col
    
    sql_content = f"""-- NOW Foodså•†å“ãƒ‡ãƒ¼ã‚¿ï¼ˆiHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
-- ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now()}
-- ç·å•†å“æ•°: {len(df)}ä»¶

-- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢  
DELETE FROM user_supplements;
DELETE FROM supplement_nutrients;
DELETE FROM supplements;

-- NOW Foodså•†å“ã‚’æŠ•å…¥
INSERT INTO supplements (dsld_id, name_en, name_ja, brand, serving_size, category) VALUES
"""
    
    for i, row in df.iterrows():
        try:
            # å•†å“å
            product_name = str(row[title_col]) if title_col else f"Product {i+1}"
            product_name = product_name.replace("'", "''")  # SQLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰
            brand = str(row[brand_col]) if brand_col else "NOW Foods"
            brand = brand.replace("'", "''")
            
            # DSLD IDç”Ÿæˆ
            dsld_id = f"IHERB_{i+1:05d}"
            
            # UPC/ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æƒ…å ±ãŒã‚ã‚Œã°ä½¿ç”¨
            if upc_col and pd.notna(row[upc_col]):
                upc_value = str(row[upc_col])
                if upc_value.isdigit() and len(upc_value) >= 8:
                    dsld_id = f"IHERB_{upc_value}"
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
            product_upper = product_name.upper()
            if any(term in product_upper for term in ['VITAMIN C', 'ASCORBIC']):
                category = 'vitamins'
            elif any(term in product_upper for term in ['VITAMIN D', 'D3', 'D-3']):
                category = 'vitamins'
            elif any(term in product_upper for term in ['MAGNESIUM', 'MAG ']):
                category = 'minerals'
            elif any(term in product_upper for term in ['OMEGA', 'FISH OIL']):
                category = 'fatty_acids'
            else:
                category = 'supplements'
            
            sql_content += f"('{dsld_id}', '{product_name}', '{product_name}', '{brand}', '1 serving', '{category}')"
            
            if i < len(df) - 1:
                sql_content += ",\n"
            else:
                sql_content += ";\n"
                
        except Exception as e:
            print(f"âš ï¸ è¡Œ {i} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    sql_content += """
-- ãƒ‡ãƒ¼ã‚¿ç¢ºèª
SELECT brand, COUNT(*) as count FROM supplements GROUP BY brand ORDER BY count DESC;
SELECT * FROM supplements WHERE brand LIKE '%NOW%' ORDER BY name_ja LIMIT 20;

-- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ¤œç´¢ãƒ†ã‚¹ãƒˆç”¨
SELECT * FROM supplements WHERE dsld_id LIKE '%19121619%' OR name_en LIKE '%Vitamin C%' LIMIT 5;
"""
    
    with open('import_iherb_data.sql', 'w', encoding='utf-8') as f:
        f.write(sql_content)
    
    print("âœ… import_iherb_data.sql ã‚’ç”Ÿæˆå®Œäº†")
    print(f"ğŸ“Š {len(df)}ä»¶ã®NOW Foodså•†å“ã‚’SQLåŒ–")

if __name__ == "__main__":
    print("ğŸš€ Kaggle iHerbãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†é–‹å§‹")
    print("=" * 60)
    
    if extract_and_process_iherb_data():
        print("\nğŸ‰ å‡¦ç†å®Œäº†!")
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. import_iherb_data.sql ã‚’Supabaseã§å®Ÿè¡Œ")
        print("2. ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ")
    else:
        print("\nğŸ“¥ æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™")
        print("ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")